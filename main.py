import typer
import json
from pathlib import Path
from rich import print

from config import settings
from workflows import get_llm, load_and_split_documents, run_single_round_analysis, run_multi_round_analysis_with_memory, run_multi_round_analysis_without_memory
from langchain.prompts import ChatPromptTemplate

# åˆ›å»ºTyperåº”ç”¨å®ä¾‹
app = typer.Typer(help="æ¨¡å—åŒ–ã€å¯æ‰©å±•çš„LLMæ–‡æ¡£åˆ†æå·¥ä½œæµ")

def save_results(output_path: Path, filename: str, results: dict):
    """ä¿å­˜ç»“æœåˆ°txtå’Œjsonæ–‡ä»¶ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰"""
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜JSONç»“æœ
    json_filepath = output_path / f"{filename}.json"
    with open(json_filepath, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"âœ… ç»“æ„åŒ–ç»“æœå·²ä¿å­˜åˆ°: [bold green]{json_filepath}[/bold green]")
    
    # ä¿å­˜å¯è¯»çš„TXTæŠ¥å‘Š
    txt_filepath = output_path / f"{filename}.txt"
    with open(txt_filepath, 'w', encoding='utf-8') as f:
        f.write(f"æ–‡ä»¶åˆ†ææŠ¥å‘Š: {filename}\n")
        if "memory_type" in results:
            f.write(f"è®°å¿†ç±»å‹: {results['memory_type']}\n")
        f.write("="*50 + "\n\n")
        
        if "single_round_result" in results:
            f.write(results["single_round_result"])
        elif "multi_round_results" in results:
            for round_data in results["multi_round_results"]:
                f.write(f"--- ç¬¬ {round_data['round']} è½®åˆ†æ ---\n")
                if "memory_type" in round_data:
                    f.write(f"è®°å¿†ç±»å‹: {round_data['memory_type']}\n")
                f.write(f"Promptæ¨¡æ¿:\n{round_data['prompt_template']}\n\n")
                f.write(f"åˆ†æç»“æœ:\n{round_data['result']}\n\n")
                
                # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œæ˜¾ç¤ºå¯¹è¯å†å²ä¿¡æ¯
                if "conversation_history" in round_data:
                    if isinstance(round_data["conversation_history"], list):
                        f.write(f"å¯¹è¯å†å²é•¿åº¦: {len(round_data['conversation_history'])} æ¡æ¶ˆæ¯\n")
                    else:
                        f.write(f"å¯¹è¯å†å²: {round_data['conversation_history']}\n")
                
                f.write("="*50 + "\n\n")
    print(f"âœ… è¯¦ç»†æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜åˆ°: [bold green]{txt_filepath}[/bold green]")


def save_file_results(output_path: Path, file_result: dict):
    """ä¿å­˜å•ä¸ªæ–‡ä»¶çš„åˆ†æç»“æœ"""
    output_path.mkdir(parents=True, exist_ok=True)
    
    source_file = file_result["source_file"]
    file_path = Path(source_file)
    filename = file_path.stem  # è·å–ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
    
    # ä¿å­˜JSONç»“æœ
    json_filepath = output_path / f"{filename}.json"
    with open(json_filepath, 'w', encoding='utf-8') as f:
        json.dump(file_result, f, ensure_ascii=False, indent=2)
    print(f"âœ… æ–‡ä»¶ {filename} çš„JSONç»“æœå·²ä¿å­˜åˆ°: [bold green]{json_filepath}[/bold green]")
    
    # ä¿å­˜TXTæŠ¥å‘Š
    txt_filepath = output_path / f"{filename}.txt"
    with open(txt_filepath, 'w', encoding='utf-8') as f:
        f.write(f"æ–‡ä»¶åˆ†ææŠ¥å‘Š: {filename}\n")
        f.write(f"æºæ–‡ä»¶: {source_file}\n")
        if "memory_type" in file_result:
            f.write(f"è®°å¿†ç±»å‹: {file_result['memory_type']}\n")
        f.write("="*50 + "\n\n")
        
        for round_data in file_result["analysis_history"]:
            round_type = round_data.get('round_type', f'ç¬¬{round_data["round"]}è½®')
            f.write(f"--- ç¬¬ {round_data['round']} è½®åˆ†æ ({round_type}) ---\n")
            f.write(f"åˆ†æç»“æœ:\n{round_data['result']}\n\n")
            
            # æ˜¾ç¤ºå¯¹è¯å†å²ä¿¡æ¯
            if "conversation_history" in round_data:
                if isinstance(round_data["conversation_history"], list):
                    f.write(f"å¯¹è¯å†å²é•¿åº¦: {len(round_data['conversation_history'])} æ¡æ¶ˆæ¯\n")
                else:
                    f.write(f"å¯¹è¯å†å²: {round_data['conversation_history']}\n")
            
            f.write("="*50 + "\n\n")
    print(f"âœ… æ–‡ä»¶ {filename} çš„æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜åˆ°: [bold green]{txt_filepath}[/bold green]")


@app.command(name="single-round", help="å¯¹æŒ‡å®šç›®å½•çš„æ–‡æ¡£è¿›è¡Œå•è½®æ‰¹é‡åˆ†æã€‚")
def single_round():
    """æ‰§è¡Œå•è½®åˆ†æ"""
    print("ğŸš€ [bold blue]å¯åŠ¨å•è½®åˆ†æå·¥ä½œæµ...[/bold blue]")
    
    # 1. åŠ è½½é…ç½®å’Œåˆå§‹åŒ–LLM
    llm = get_llm(settings.llm_provider)
    output_path = settings.paths.output_dir / "single_round"
    
    # 2. åŠ è½½å¹¶åˆ†å‰²æ–‡æ¡£
    print(f"ğŸ“‚ æ­£åœ¨ä» [yellow]{settings.paths.input_dir}[/yellow] åŠ è½½æ–‡æ¡£...")
    docs = load_and_split_documents(settings)
    print(f"ğŸ“„ å…±åŠ è½½å¹¶åˆ†å‰²æˆ {len(docs)} ä¸ªæ–‡æ¡£å—ã€‚")

    # 3. åŠ è½½Promptæ¨¡æ¿
    try:
        # è¯»å–prompt1.txtæ–‡ä»¶
        prompt1_path = settings.paths.prompt_dir / "prompt1.txt"
        prompt_text = prompt1_path.read_text(encoding='utf-8')
        # æ³¨æ„ï¼šè¿™é‡Œçš„æ¨¡æ¿éœ€è¦åŒ…å« {text} å˜é‡ä¾› map_reduce é“¾ä½¿ç”¨
        prompt_template = ChatPromptTemplate.from_template(prompt_text)
    except FileNotFoundError:
        print(f"âŒ [bold red]é”™è¯¯: Promptæ–‡ä»¶æœªæ‰¾åˆ° -> {prompt1_path}[/bold red]")
        raise typer.Exit(code=1)

    # 4. æ‰§è¡Œåˆ†æ
    print("ğŸ§  æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œåˆ†æï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")
    file_results = run_single_round_analysis(docs, prompt_template, llm)
    
    # 5. å•ç‹¬ä¿å­˜æ¯ä¸ªæ–‡ä»¶çš„ç»“æœ
    output_path.mkdir(parents=True, exist_ok=True)
    
    for file_result in file_results:
        source = file_result["source"]
        result = file_result["result"]
        
        # ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ–‡ä»¶å
        file_path = Path(source)
        filename = file_path.stem  # è·å–ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
        
        # ä¿å­˜å•ä¸ªæ–‡ä»¶çš„JSONç»“æœ
        json_filepath = output_path / f"{filename}.json"
        file_data = {
            "source_file": source,
            "prompt_file": str(settings.paths.prompt_dir / "prompt1.txt"),
            "analysis_result": result
        }
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(file_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ–‡ä»¶ {filename} çš„JSONç»“æœå·²ä¿å­˜åˆ°: [bold green]{json_filepath}[/bold green]")
        
        # ä¿å­˜å•ä¸ªæ–‡ä»¶çš„TXTæŠ¥å‘Š
        txt_filepath = output_path / f"{filename}.txt"
        with open(txt_filepath, 'w', encoding='utf-8') as f:
            f.write(f"æ–‡ä»¶åˆ†ææŠ¥å‘Š: {filename}\n")
            f.write(f"æºæ–‡ä»¶: {source}\n")
            f.write("="*50 + "\n\n")
            f.write(result)
        print(f"âœ… æ–‡ä»¶ {filename} çš„æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜åˆ°: [bold green]{txt_filepath}[/bold green]")
    
    print(f"\nğŸ‰ [bold green]å•è½®åˆ†æå®Œæˆï¼å…±å¤„ç†äº† {len(file_results)} ä¸ªæ–‡ä»¶ã€‚[/bold green]")


@app.command(name="multi-round", help="å¯¹æ–‡æ¡£è¿›è¡Œå¤šè½®ã€é€’è¿›å¼åˆ†æï¼ˆä½¿ç”¨å®Œæ•´å¯¹è¯è®°å¿†ï¼‰ã€‚")
def multi_round():
    """æ‰§è¡Œå¤šè½®åˆ†æï¼ˆä½¿ç”¨å®Œæ•´å¯¹è¯è®°å¿†ï¼‰"""
    print("ğŸš€ [bold magenta]å¯åŠ¨å¤šè½®åˆ†æå·¥ä½œæµï¼ˆå®Œæ•´å¯¹è¯è®°å¿†ï¼‰...[/bold magenta]")
    
    # 1. åŠ è½½é…ç½®å’Œåˆå§‹åŒ–LLM
    llm = get_llm(settings.llm_provider)
    output_path = settings.paths.output_dir / "multi_round"
    prompt_files = sorted(settings.paths.prompt_dir.glob("round*.txt"))

    if not prompt_files:
        print(f"âŒ [bold red]é”™è¯¯: åœ¨ {settings.paths.prompt_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• 'round*.txt' æ–‡ä»¶ã€‚[/bold red]")
        raise typer.Exit(code=1)

    # 2. åŠ è½½å¹¶åˆ†å‰²æ–‡æ¡£
    print(f"ğŸ“‚ æ­£åœ¨ä» [yellow]{settings.paths.input_dir}[/yellow] åŠ è½½æ–‡æ¡£...")
    docs = load_and_split_documents(settings)
    print(f"ğŸ“„ å…±åŠ è½½å¹¶åˆ†å‰²æˆ {len(docs)} ä¸ªæ–‡æ¡£å—ã€‚")

    # 3. åŠ è½½æ‰€æœ‰è½®æ¬¡çš„Promptæ¨¡æ¿
    # æ³¨æ„ï¼šä½¿ç”¨å¯¹è¯è®°å¿†æ—¶ï¼Œæ¨¡æ¿ä¸éœ€è¦åŒ…å« {previous_results} å˜é‡
    round_prompts = []
    print("ğŸ“ åŠ è½½Promptæ¨¡æ¿:")
    for pf in prompt_files:
        print(f"  - {pf.name}")
        round_prompts.append(ChatPromptTemplate.from_template(pf.read_text(encoding='utf-8')))
        
    # 4. æ‰§è¡Œå¤šè½®åˆ†æï¼ˆä½¿ç”¨å®Œæ•´å¯¹è¯è®°å¿†ï¼‰
    print("ğŸ§  ä½¿ç”¨å®Œæ•´å¯¹è¯è®°å¿†è¿›è¡Œå¤šè½®åˆ†æ...")
    final_results_list = run_multi_round_analysis_with_memory(
        docs, round_prompts, llm, memory_type="buffer"
    )
    
    # 5. ç»“æœå·²å®æ—¶ä¿å­˜ï¼Œè¿™é‡Œåªæ˜¾ç¤ºå®Œæˆä¿¡æ¯
    print(f"\nğŸ‰ [bold green]å¤šè½®åˆ†æå®Œæˆï¼å…±å¤„ç†äº† {len(final_results_list)} ä¸ªæ–‡ä»¶ã€‚ï¼ˆä½¿ç”¨å®Œæ•´å¯¹è¯è®°å¿†ï¼‰[/bold green]")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: [bold green]{output_path}[/bold green]")


@app.command(name="multi-round-advanced", help="å¯¹æ–‡æ¡£è¿›è¡Œå¤šè½®åˆ†æï¼Œæ”¯æŒé€‰æ‹©ä¸åŒçš„å¯¹è¯è®°å¿†ç±»å‹ã€‚")
def multi_round_advanced(
    memory_type: str = typer.Option(
        "buffer", 
        "--memory-type", 
        "-m", 
        help="å¯¹è¯è®°å¿†ç±»å‹: buffer(å®Œæ•´è®°å¿†), window(çª—å£è®°å¿†), summary(æ‘˜è¦è®°å¿†)"
    )
):
    """æ‰§è¡Œå¤šè½®åˆ†æï¼ˆæ”¯æŒé€‰æ‹©è®°å¿†ç±»å‹ï¼‰"""
    print(f"ğŸš€ [bold magenta]å¯åŠ¨å¤šè½®åˆ†æå·¥ä½œæµï¼ˆè®°å¿†ç±»å‹: {memory_type}ï¼‰...[/bold magenta]")
    
    # 1. åŠ è½½é…ç½®å’Œåˆå§‹åŒ–LLM
    llm = get_llm(settings.llm_provider)
    output_path = settings.paths.output_dir / f"multi_round_{memory_type}"
    prompt_files = sorted(settings.paths.prompt_dir.glob("round*.txt"))

    if not prompt_files:
        print(f"âŒ [bold red]é”™è¯¯: åœ¨ {settings.paths.prompt_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• 'round*.txt' æ–‡ä»¶ã€‚[/bold red]")
        raise typer.Exit(code=1)

    # 2. åŠ è½½å¹¶åˆ†å‰²æ–‡æ¡£
    print(f"ğŸ“‚ æ­£åœ¨ä» [yellow]{settings.paths.input_dir}[/yellow] åŠ è½½æ–‡æ¡£...")
    docs = load_and_split_documents(settings)
    print(f"ğŸ“„ å…±åŠ è½½å¹¶åˆ†å‰²æˆ {len(docs)} ä¸ªæ–‡æ¡£å—ã€‚")

    # 3. åŠ è½½æ‰€æœ‰è½®æ¬¡çš„Promptæ¨¡æ¿
    round_prompts = []
    print("ğŸ“ åŠ è½½Promptæ¨¡æ¿:")
    for pf in prompt_files:
        print(f"  - {pf.name}")
        round_prompts.append(ChatPromptTemplate.from_template(pf.read_text(encoding='utf-8')))
        
    # 4. æ‰§è¡Œå¤šè½®åˆ†æï¼ˆä½¿ç”¨æŒ‡å®šè®°å¿†ç±»å‹ï¼‰
    print(f"ğŸ§  ä½¿ç”¨ {memory_type} è®°å¿†ç±»å‹è¿›è¡Œå¤šè½®åˆ†æ...")
    final_results_list = run_multi_round_analysis_with_memory(
        docs, round_prompts, llm, memory_type=memory_type
    )
    
    # 5. ç»“æœå·²å®æ—¶ä¿å­˜ï¼Œè¿™é‡Œåªæ˜¾ç¤ºå®Œæˆä¿¡æ¯
    print(f"\nğŸ‰ [bold green]å¤šè½®åˆ†æå®Œæˆï¼å…±å¤„ç†äº† {len(final_results_list)} ä¸ªæ–‡ä»¶ã€‚ï¼ˆä½¿ç”¨ {memory_type} è®°å¿†ç±»å‹ï¼‰[/bold green]")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: [bold green]{output_path}[/bold green]")


@app.command(name="multi-round-no-memory", help="å¯¹æ–‡æ¡£è¿›è¡Œå¤šè½®åˆ†æï¼Œä¸ä½¿ç”¨å¯¹è¯è®°å¿†ï¼Œé€šè¿‡æ˜¾å¼ä¼ é€’ä¹‹å‰è½®æ¬¡ç»“æœã€‚")
def multi_round_no_memory(
    max_concurrent: int = typer.Option(
        5, 
        "--max-concurrent", 
        "-c", 
        help="æœ€å¤§å¹¶å‘æ•°é‡ï¼Œæ§åˆ¶åŒæ—¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆé»˜è®¤: 5ï¼‰"
    )
):
    """æ‰§è¡Œå¤šè½®åˆ†æï¼ˆä¸ä½¿ç”¨å¯¹è¯è®°å¿†ï¼Œæ˜¾å¼ä¼ é€’ä¹‹å‰è½®æ¬¡ç»“æœï¼‰"""
    print("ğŸš€ [bold cyan]å¯åŠ¨å¤šè½®åˆ†æå·¥ä½œæµï¼ˆæ— è®°å¿†æ¨¡å¼ï¼‰...[/bold cyan]")
    
    # 1. åŠ è½½é…ç½®å’Œåˆå§‹åŒ–LLM
    llm = get_llm(settings.llm_provider)
    output_path = settings.paths.output_dir / "multi_round_no_memory"
    prompt_files = sorted(settings.paths.prompt_dir.glob("round*.txt"))

    if not prompt_files:
        print(f"âŒ [bold red]é”™è¯¯: åœ¨ {settings.paths.prompt_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• 'round*.txt' æ–‡ä»¶ã€‚[/bold red]")
        raise typer.Exit(code=1)

    # 2. åŠ è½½å¹¶åˆ†å‰²æ–‡æ¡£
    print(f"ğŸ“‚ æ­£åœ¨ä» [yellow]{settings.paths.input_dir}[/yellow] åŠ è½½æ–‡æ¡£...")
    docs = load_and_split_documents(settings)
    print(f"ğŸ“„ å…±åŠ è½½å¹¶åˆ†å‰²æˆ {len(docs)} ä¸ªæ–‡æ¡£å—ã€‚")

    # 3. åŠ è½½æ‰€æœ‰è½®æ¬¡çš„Promptæ¨¡æ¿
    # æ³¨æ„ï¼šæ— è®°å¿†æ¨¡å¼ä¸‹ï¼Œæ¨¡æ¿å¯ä»¥åŒ…å« {previous_results} å˜é‡æ¥å¼•ç”¨ä¹‹å‰è½®æ¬¡çš„ç»“æœ
    round_prompts = []
    print("ğŸ“ åŠ è½½Promptæ¨¡æ¿:")
    for pf in prompt_files:
        print(f"  - {pf.name}")
        round_prompts.append(ChatPromptTemplate.from_template(pf.read_text(encoding='utf-8')))
        
    # 4. æ‰§è¡Œå¤šè½®åˆ†æï¼ˆä¸ä½¿ç”¨å¯¹è¯è®°å¿†ï¼‰
    print(f"ğŸ§  ä½¿ç”¨æ— è®°å¿†æ¨¡å¼è¿›è¡Œå¤šè½®åˆ†æï¼ˆæ˜¾å¼ä¼ é€’ä¹‹å‰è½®æ¬¡ç»“æœï¼Œæœ€å¤§å¹¶å‘: {max_concurrent}ï¼‰...")
    final_results_list = run_multi_round_analysis_without_memory(
        docs, round_prompts, llm, max_concurrent
    )
    
    # 5. ç»“æœå·²å®æ—¶ä¿å­˜ï¼Œè¿™é‡Œåªæ˜¾ç¤ºå®Œæˆä¿¡æ¯
    print(f"\nğŸ‰ [bold green]å¤šè½®åˆ†æå®Œæˆï¼å…±å¤„ç†äº† {len(final_results_list)} ä¸ªæ–‡ä»¶ã€‚ï¼ˆæ— è®°å¿†æ¨¡å¼ï¼‰[/bold green]")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: [bold green]{output_path}[/bold green]")


if __name__ == "__main__":
    app()